{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b9c3f4",
   "metadata": {},
   "source": [
    "# ü§ñ 01 ‚Äî Data Exploration: Manipulator Health Monitoring (EDA)\n",
    "\n",
    "This notebook performs the **Exploratory Data Analysis (EDA)** phase on the raw UR5 manipulator sensor data, sourced from NIST.\n",
    "\n",
    "The primary goals are to:\n",
    "1.  Consolidate and inspect the raw, multi-file sensor readings.\n",
    "2.  Assess data quality, memory usage, and column types.\n",
    "3.  Perform initial data parsing to convert list-like sensor readings (e.g., joint positions, forces) into separate, usable numeric columns.\n",
    "4.  Save the cleaned, structured dataset for subsequent preprocessing and feature engineering.\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Table of Contents\n",
    "\n",
    "1.  [Setup and Configuration](#1.-‚öôÔ∏è-Setup-and-Configuration)\n",
    "2.  [Data Loading and Concatenation](#2.-üíæ-Data-Loading-and-Concatenation)\n",
    "3.  [Basic Data Inspection](#3.-üìä-Basic-Data-Inspection)\n",
    "4.  [Data Parsing and List Expansion](#4.-üìù-Data-Parsing-and-List-Expansion)\n",
    "5.  [Save Processed Data](#5.-üíæ-Save-Processed-Data)\n",
    "6.  [Summary](#6.-üßæ-Summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f7bcf",
   "metadata": {},
   "source": [
    "## 1. ‚öôÔ∏è Setup and Configuration\n",
    "\n",
    "Import necessary libraries for data handling, file management, visualization, and specialized parsing. We configure Pandas and Seaborn for professional display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup_imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast # For safe evaluation of list-like strings\n",
    "from tqdm.auto import tqdm # For tracking progress during large operations\n",
    "\n",
    "# File handling\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set(style=\"whitegrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading_intro",
   "metadata": {},
   "source": [
    "## 2. üíæ Data Loading and Concatenation\n",
    "\n",
    "The raw sensor data for this project is stored across multiple CSV files (`*.csv`), where each file represents a single test run. We must load and merge all records into a single DataFrame using a custom parsing function to handle the non-standard list/tuple structure within the CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d5a3c2-2e16-49b0-9a7f-23a00b8eb334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Found 18 raw sensor data files.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555521317257435e9cca22071ab1ffd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading and parsing files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined sensor data shape: (153658, 13)\n"
     ]
    }
   ],
   "source": [
    "# Function to safely parse complex list-like strings in the CSV\n",
    "def parse_sensor_line(line):\n",
    "    \"\"\"Cleans up and safely evaluates a single line of the non-standard sensor CSV.\"\"\"\n",
    "    line = line.strip().lstrip('(').rstrip(')')\n",
    "    try:\n",
    "        # Wrap the content to create a valid Python list string for literal_eval\n",
    "        return ast.literal_eval(f\"[{line}]\")\n",
    "    except:\n",
    "        # Log error or return None if parsing fails\n",
    "        return None \n",
    "\n",
    "# Glob all sensor CSV files\n",
    "csv_files = glob.glob(\"../data/raw/sensor_data/*.csv\")\n",
    "print(f\"üìÅ Found {len(csv_files)} raw sensor data files.\")\n",
    "\n",
    "# Define columns (required to load the data without a header)\n",
    "SENSOR_COLUMNS = [\n",
    "    \"ROBOT_TIME\", \"ROBOT_TARGET_JOINT_POSITIONS\", \"ROBOT_ACTUAL_JOINT_POSITIONS\",\n",
    "    \"ROBOT_TARGET_JOINT_VELOCITIES\", \"ROBOT_ACTUAL_JOINT_VELOCITIES\",\n",
    "    \"ROBOT_TARGET_JOINT_CURRENTS\", \"ROBOT_ACTUAL_JOINT_CURRENTS\",\n",
    "    \"ROBOT_TARGET_JOINT_ACCELERATIONS\", \"ROBOT_TARGET_JOINT_TORQUES\",\n",
    "    \"ROBOT_JOINT_CONTROL_CURRENT\", \"ROBOT_CARTESIAN_COORD_TOOL\",\n",
    "    \"ROBOT_TCP_FORCE\", \"ROBOT_JOINT_TEMP\"\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "NUM_COLUMNS = len(SENSOR_COLUMNS)\n",
    "\n",
    "# --- REVERTED TO RELIABLE FILE-BY-FILE READING LOOP ---\n",
    "for fpath in tqdm(csv_files, desc=\"Loading and parsing files\"):\n",
    "    try:\n",
    "        with open(fpath, \"r\") as f:\n",
    "            for line in f:\n",
    "                parsed = parse_sensor_line(line)\n",
    "                # Only append if parsing was successful (i.e., not None)\n",
    "                if parsed is not None and len(parsed) == NUM_COLUMNS:\n",
    "                    all_data.append(parsed)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading file {fpath}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Create final DataFrame using the robustly cleaned list\n",
    "sensor_data = pd.DataFrame(all_data, columns=SENSOR_COLUMNS)\n",
    "\n",
    "# ... (Rest of your metadata loading code remains the same)\n",
    "header_path = \"../data/raw/header/ur5testresult_header.xlsx\"\n",
    "summary_path = \"../data/raw/summary/calculated_deviation_of_actual_position_to_nominal_position.xlsx\"\n",
    "# We wrap these in a try/except because they are not strictly necessary for the EDA flow\n",
    "try:\n",
    "    header_df = pd.read_excel(header_path)\n",
    "    summary_df = pd.read_excel(summary_path)\n",
    "except Exception as e:\n",
    "    print(f\"Metadata loading skipped (File not found or I/O error): {e}\")\n",
    "\n",
    "\n",
    "print(f\"‚úÖ Combined sensor data shape: {sensor_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic_inspection_intro",
   "metadata": {},
   "source": [
    "## 3. üìä Basic Data Inspection\n",
    "\n",
    "Initial inspection reveals the sheer volume of data and the presence of `object` types, which represent the list-like sensor readings that need to be expanded into individual numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "basic_inspection_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset shape: (153658, 13)\n",
      "üíæ Estimated memory usage: 239.15 MB\n",
      "\n",
      "üìä Column type distribution:\n",
      "object    13\n",
      "Name: count, dtype: int64\n",
      "First 3 rows (raw structure):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROBOT_TIME</th>\n",
       "      <th>ROBOT_TARGET_JOINT_POSITIONS</th>\n",
       "      <th>ROBOT_ACTUAL_JOINT_POSITIONS</th>\n",
       "      <th>ROBOT_TARGET_JOINT_VELOCITIES</th>\n",
       "      <th>ROBOT_ACTUAL_JOINT_VELOCITIES</th>\n",
       "      <th>ROBOT_TARGET_JOINT_CURRENTS</th>\n",
       "      <th>ROBOT_ACTUAL_JOINT_CURRENTS</th>\n",
       "      <th>ROBOT_TARGET_JOINT_ACCELERATIONS</th>\n",
       "      <th>ROBOT_TARGET_JOINT_TORQUES</th>\n",
       "      <th>ROBOT_JOINT_CONTROL_CURRENT</th>\n",
       "      <th>ROBOT_CARTESIAN_COORD_TOOL</th>\n",
       "      <th>ROBOT_TCP_FORCE</th>\n",
       "      <th>ROBOT_JOINT_TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[13867.472]</td>\n",
       "      <td>[-26.880068716264294, -79.91160892471794, 57.0...</td>\n",
       "      <td>[-26.881428894723115, -79.91090832767539, 57.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, -0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.433830495651467e-17, -2.2138144127730115, -...</td>\n",
       "      <td>[-0.2914353609085083, -2.640852928161621, -2.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.850164985011539e-16, -25.67417061620775, -1...</td>\n",
       "      <td>[-0.2914353609085083, -2.64982008934021, -2.08...</td>\n",
       "      <td>[-0.6376844833673514, 0.27758034088384226, 0.7...</td>\n",
       "      <td>[1.7623931851118197, -6.732057848264457, -14.2...</td>\n",
       "      <td>[27.37999153137207, 28.78999137878418, 28.9298...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[13867.48]</td>\n",
       "      <td>[-26.880068716264294, -79.91160892471794, 57.0...</td>\n",
       "      <td>[-26.87937983797211, -79.9095422898414, 57.091...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, -0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.433830495651467e-17, -2.2138144127730115, -...</td>\n",
       "      <td>[-0.2847099304199219, -2.64982008934021, -2.06...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.850164985011539e-16, -25.67417061620775, -1...</td>\n",
       "      <td>[-0.2914353609085083, -2.64982008934021, -2.07...</td>\n",
       "      <td>[-0.6376930015017775, 0.27756734465474087, 0.7...</td>\n",
       "      <td>[0.9792112067350713, -6.221806455327369, -13.3...</td>\n",
       "      <td>[27.37999153137207, 28.78999137878418, 28.9298...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[13867.488]</td>\n",
       "      <td>[-26.880068716264294, -79.91160892471794, 57.0...</td>\n",
       "      <td>[-26.88006285688911, -79.9088592709244, 57.091...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, -0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.433830495651467e-17, -2.2138144127730115, -...</td>\n",
       "      <td>[-0.2959190011024475, -2.663270950317383, -2.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.850164985011539e-16, -25.67417061620775, -1...</td>\n",
       "      <td>[-0.2914353609085083, -2.64982008934021, -2.07...</td>\n",
       "      <td>[-0.6376927034316546, 0.27757289684249814, 0.7...</td>\n",
       "      <td>[0.448984913981216, -6.268759803739754, -13.17...</td>\n",
       "      <td>[27.37999153137207, 28.78999137878418, 28.9298...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROBOT_TIME                       ROBOT_TARGET_JOINT_POSITIONS  \\\n",
       "0  [13867.472]  [-26.880068716264294, -79.91160892471794, 57.0...   \n",
       "1   [13867.48]  [-26.880068716264294, -79.91160892471794, 57.0...   \n",
       "2  [13867.488]  [-26.880068716264294, -79.91160892471794, 57.0...   \n",
       "\n",
       "                        ROBOT_ACTUAL_JOINT_POSITIONS  \\\n",
       "0  [-26.881428894723115, -79.91090832767539, 57.0...   \n",
       "1  [-26.87937983797211, -79.9095422898414, 57.091...   \n",
       "2  [-26.88006285688911, -79.9088592709244, 57.091...   \n",
       "\n",
       "    ROBOT_TARGET_JOINT_VELOCITIES    ROBOT_ACTUAL_JOINT_VELOCITIES  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 0.0, -0.0, 0.0, 0.0, 0.0]   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 0.0, -0.0, 0.0, 0.0, 0.0]   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 0.0, -0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                         ROBOT_TARGET_JOINT_CURRENTS  \\\n",
       "0  [2.433830495651467e-17, -2.2138144127730115, -...   \n",
       "1  [2.433830495651467e-17, -2.2138144127730115, -...   \n",
       "2  [2.433830495651467e-17, -2.2138144127730115, -...   \n",
       "\n",
       "                         ROBOT_ACTUAL_JOINT_CURRENTS  \\\n",
       "0  [-0.2914353609085083, -2.640852928161621, -2.0...   \n",
       "1  [-0.2847099304199219, -2.64982008934021, -2.06...   \n",
       "2  [-0.2959190011024475, -2.663270950317383, -2.0...   \n",
       "\n",
       "  ROBOT_TARGET_JOINT_ACCELERATIONS  \\\n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                          ROBOT_TARGET_JOINT_TORQUES  \\\n",
       "0  [2.850164985011539e-16, -25.67417061620775, -1...   \n",
       "1  [2.850164985011539e-16, -25.67417061620775, -1...   \n",
       "2  [2.850164985011539e-16, -25.67417061620775, -1...   \n",
       "\n",
       "                         ROBOT_JOINT_CONTROL_CURRENT  \\\n",
       "0  [-0.2914353609085083, -2.64982008934021, -2.08...   \n",
       "1  [-0.2914353609085083, -2.64982008934021, -2.07...   \n",
       "2  [-0.2914353609085083, -2.64982008934021, -2.07...   \n",
       "\n",
       "                          ROBOT_CARTESIAN_COORD_TOOL  \\\n",
       "0  [-0.6376844833673514, 0.27758034088384226, 0.7...   \n",
       "1  [-0.6376930015017775, 0.27756734465474087, 0.7...   \n",
       "2  [-0.6376927034316546, 0.27757289684249814, 0.7...   \n",
       "\n",
       "                                     ROBOT_TCP_FORCE  \\\n",
       "0  [1.7623931851118197, -6.732057848264457, -14.2...   \n",
       "1  [0.9792112067350713, -6.221806455327369, -13.3...   \n",
       "2  [0.448984913981216, -6.268759803739754, -13.17...   \n",
       "\n",
       "                                    ROBOT_JOINT_TEMP  \n",
       "0  [27.37999153137207, 28.78999137878418, 28.9298...  \n",
       "1  [27.37999153137207, 28.78999137878418, 28.9298...  \n",
       "2  [27.37999153137207, 28.78999137878418, 28.9298...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"‚úÖ Dataset shape:\", sensor_data.shape)\n",
    "\n",
    "# Memory usage (deep calculation)\n",
    "mem_usage = sensor_data.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"üíæ Estimated memory usage: {mem_usage:.2f} MB\")\n",
    "\n",
    "# Dtypes overview\n",
    "print(\"\\nüìä Column type distribution:\")\n",
    "print(sensor_data.dtypes.value_counts())\n",
    "\n",
    "# Preview\n",
    "print(\"First 3 rows (raw structure):\")\n",
    "display(sensor_data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_quality_intro",
   "metadata": {},
   "source": [
    "### 3.2. Data Quality: Missing Values and Uniques\n",
    "\n",
    "We check for missingness and analyze unique value counts, which will highlight the columns currently holding list-like data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad53cd08-f99e-481b-bbbe-83e2f082b86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Statistical summary for ROBOT_TIME:\n",
      "No numeric columns detected yet (Data must be expanded first).\n",
      "\n",
      "‚ö†Ô∏è Missing values ratio (top 20 columns):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ROBOT_TIME                          0.0\n",
       "ROBOT_TARGET_JOINT_POSITIONS        0.0\n",
       "ROBOT_ACTUAL_JOINT_POSITIONS        0.0\n",
       "ROBOT_TARGET_JOINT_VELOCITIES       0.0\n",
       "ROBOT_ACTUAL_JOINT_VELOCITIES       0.0\n",
       "ROBOT_TARGET_JOINT_CURRENTS         0.0\n",
       "ROBOT_ACTUAL_JOINT_CURRENTS         0.0\n",
       "ROBOT_TARGET_JOINT_ACCELERATIONS    0.0\n",
       "ROBOT_TARGET_JOINT_TORQUES          0.0\n",
       "ROBOT_JOINT_CONTROL_CURRENT         0.0\n",
       "ROBOT_CARTESIAN_COORD_TOOL          0.0\n",
       "ROBOT_TCP_FORCE                     0.0\n",
       "ROBOT_JOINT_TEMP                    0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Sample Statistical summary (only ROBOT_TIME is numeric for now)\n",
    "print(\"\\nüîç Statistical summary for ROBOT_TIME:\")\n",
    "# Only describe columns that are actually numeric (ROBOT_TIME)\n",
    "numeric_cols = sensor_data.select_dtypes(include=np.number).columns\n",
    "if len(numeric_cols) > 0:\n",
    "    display(sensor_data[numeric_cols].describe().T)\n",
    "else:\n",
    "    print(\"No numeric columns detected yet (Data must be expanded first).\")\n",
    "\n",
    "# Missing values\n",
    "print(\"\\n‚ö†Ô∏è Missing values ratio (top 20 columns):\")\n",
    "missing = sensor_data.isna().mean().sort_values(ascending=False)\n",
    "display(missing.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_parsing_intro",
   "metadata": {},
   "source": [
    "## 4. üìù Data Parsing and List Expansion\n",
    "\n",
    "To make the data usable for modeling, we must expand all list-form sensor readings (e.g., 6 joint positions, 6 joint velocities) into separate, distinct numeric columns (e.g., `..._POSITIONS_1` to `..._POSITIONS_6`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "expansion_function_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_list_columns(df, columns_to_expand):\n",
    "    \"\"\"Expands list-like columns into multiple numeric columns.\"\"\"\n",
    "    expanded_dfs = []\n",
    "    \n",
    "    for col in tqdm(columns_to_expand, desc=\"Expanding list columns\"):\n",
    "        first_valid = df[col].dropna().iloc[0]\n",
    "        \n",
    "        # Check if column values are list-type \n",
    "        if isinstance(first_valid, list):\n",
    "            # Convert list-column to a DataFrame of new columns\n",
    "            expanded_df = pd.DataFrame(df[col].tolist(), \n",
    "                                       columns=[f\"{col}_{i+1}\" for i in range(len(first_valid))])\n",
    "            expanded_dfs.append(expanded_df)\n",
    "        else:\n",
    "            # If not a list (like ROBOT_TIME), keep the original scalar column\n",
    "            expanded_dfs.append(df[[col]])\n",
    "            \n",
    "    return pd.concat(expanded_dfs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applying_expansion_markdown",
   "metadata": {},
   "source": [
    "### 4.2. Applying Expansion and Final Data Cleanup\n",
    "\n",
    "We group the columns by their inherent dimensionality (e.g., 6 joints, 3 Cartesian coordinates) and apply the expansion. Crucially, we also fix the persistent data type issue in the ROBOT_TIME column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b3766-a96e-4a01-b104-9eed2bbe9d3b",
   "metadata": {},
   "source": [
    "#### 1. Data Expansion and Initial Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "applying_expansion_code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba872f9568945b4a097af30be7a3b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Expanding list columns:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final shape after expansion: (153658, 73)\n",
      "\n",
      "üìä Final Column Types and Memory Usage:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153658 entries, 0 to 153657\n",
      "Data columns (total 73 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   ROBOT_TARGET_JOINT_POSITIONS_1      153658 non-null  float64\n",
      " 1   ROBOT_TARGET_JOINT_POSITIONS_2      153658 non-null  float64\n",
      " 2   ROBOT_TARGET_JOINT_POSITIONS_3      153658 non-null  float64\n",
      " 3   ROBOT_TARGET_JOINT_POSITIONS_4      153658 non-null  float64\n",
      " 4   ROBOT_TARGET_JOINT_POSITIONS_5      153658 non-null  float64\n",
      " 5   ROBOT_TARGET_JOINT_POSITIONS_6      153658 non-null  float64\n",
      " 6   ROBOT_ACTUAL_JOINT_POSITIONS_1      153658 non-null  float64\n",
      " 7   ROBOT_ACTUAL_JOINT_POSITIONS_2      153658 non-null  float64\n",
      " 8   ROBOT_ACTUAL_JOINT_POSITIONS_3      153658 non-null  float64\n",
      " 9   ROBOT_ACTUAL_JOINT_POSITIONS_4      153658 non-null  float64\n",
      " 10  ROBOT_ACTUAL_JOINT_POSITIONS_5      153658 non-null  float64\n",
      " 11  ROBOT_ACTUAL_JOINT_POSITIONS_6      153658 non-null  float64\n",
      " 12  ROBOT_TARGET_JOINT_VELOCITIES_1     153658 non-null  float64\n",
      " 13  ROBOT_TARGET_JOINT_VELOCITIES_2     153658 non-null  float64\n",
      " 14  ROBOT_TARGET_JOINT_VELOCITIES_3     153658 non-null  float64\n",
      " 15  ROBOT_TARGET_JOINT_VELOCITIES_4     153658 non-null  float64\n",
      " 16  ROBOT_TARGET_JOINT_VELOCITIES_5     153658 non-null  float64\n",
      " 17  ROBOT_TARGET_JOINT_VELOCITIES_6     153658 non-null  float64\n",
      " 18  ROBOT_ACTUAL_JOINT_VELOCITIES_1     153658 non-null  float64\n",
      " 19  ROBOT_ACTUAL_JOINT_VELOCITIES_2     153658 non-null  float64\n",
      " 20  ROBOT_ACTUAL_JOINT_VELOCITIES_3     153658 non-null  float64\n",
      " 21  ROBOT_ACTUAL_JOINT_VELOCITIES_4     153658 non-null  float64\n",
      " 22  ROBOT_ACTUAL_JOINT_VELOCITIES_5     153658 non-null  float64\n",
      " 23  ROBOT_ACTUAL_JOINT_VELOCITIES_6     153658 non-null  float64\n",
      " 24  ROBOT_TARGET_JOINT_CURRENTS_1       153658 non-null  float64\n",
      " 25  ROBOT_TARGET_JOINT_CURRENTS_2       153658 non-null  float64\n",
      " 26  ROBOT_TARGET_JOINT_CURRENTS_3       153658 non-null  float64\n",
      " 27  ROBOT_TARGET_JOINT_CURRENTS_4       153658 non-null  float64\n",
      " 28  ROBOT_TARGET_JOINT_CURRENTS_5       153658 non-null  float64\n",
      " 29  ROBOT_TARGET_JOINT_CURRENTS_6       153658 non-null  float64\n",
      " 30  ROBOT_ACTUAL_JOINT_CURRENTS_1       153658 non-null  float64\n",
      " 31  ROBOT_ACTUAL_JOINT_CURRENTS_2       153658 non-null  float64\n",
      " 32  ROBOT_ACTUAL_JOINT_CURRENTS_3       153658 non-null  float64\n",
      " 33  ROBOT_ACTUAL_JOINT_CURRENTS_4       153658 non-null  float64\n",
      " 34  ROBOT_ACTUAL_JOINT_CURRENTS_5       153658 non-null  float64\n",
      " 35  ROBOT_ACTUAL_JOINT_CURRENTS_6       153658 non-null  float64\n",
      " 36  ROBOT_TARGET_JOINT_ACCELERATIONS_1  153658 non-null  float64\n",
      " 37  ROBOT_TARGET_JOINT_ACCELERATIONS_2  153658 non-null  float64\n",
      " 38  ROBOT_TARGET_JOINT_ACCELERATIONS_3  153658 non-null  float64\n",
      " 39  ROBOT_TARGET_JOINT_ACCELERATIONS_4  153658 non-null  float64\n",
      " 40  ROBOT_TARGET_JOINT_ACCELERATIONS_5  153658 non-null  float64\n",
      " 41  ROBOT_TARGET_JOINT_ACCELERATIONS_6  153658 non-null  float64\n",
      " 42  ROBOT_TARGET_JOINT_TORQUES_1        153658 non-null  float64\n",
      " 43  ROBOT_TARGET_JOINT_TORQUES_2        153658 non-null  float64\n",
      " 44  ROBOT_TARGET_JOINT_TORQUES_3        153658 non-null  float64\n",
      " 45  ROBOT_TARGET_JOINT_TORQUES_4        153658 non-null  float64\n",
      " 46  ROBOT_TARGET_JOINT_TORQUES_5        153658 non-null  float64\n",
      " 47  ROBOT_TARGET_JOINT_TORQUES_6        153658 non-null  float64\n",
      " 48  ROBOT_JOINT_CONTROL_CURRENT_1       153658 non-null  float64\n",
      " 49  ROBOT_JOINT_CONTROL_CURRENT_2       153658 non-null  float64\n",
      " 50  ROBOT_JOINT_CONTROL_CURRENT_3       153658 non-null  float64\n",
      " 51  ROBOT_JOINT_CONTROL_CURRENT_4       153658 non-null  float64\n",
      " 52  ROBOT_JOINT_CONTROL_CURRENT_5       153658 non-null  float64\n",
      " 53  ROBOT_JOINT_CONTROL_CURRENT_6       153658 non-null  float64\n",
      " 54  ROBOT_CARTESIAN_COORD_TOOL_1        153658 non-null  float64\n",
      " 55  ROBOT_CARTESIAN_COORD_TOOL_2        153658 non-null  float64\n",
      " 56  ROBOT_CARTESIAN_COORD_TOOL_3        153658 non-null  float64\n",
      " 57  ROBOT_CARTESIAN_COORD_TOOL_4        153658 non-null  float64\n",
      " 58  ROBOT_CARTESIAN_COORD_TOOL_5        153658 non-null  float64\n",
      " 59  ROBOT_CARTESIAN_COORD_TOOL_6        153658 non-null  float64\n",
      " 60  ROBOT_TCP_FORCE_1                   153658 non-null  float64\n",
      " 61  ROBOT_TCP_FORCE_2                   153658 non-null  float64\n",
      " 62  ROBOT_TCP_FORCE_3                   153658 non-null  float64\n",
      " 63  ROBOT_TCP_FORCE_4                   153658 non-null  float64\n",
      " 64  ROBOT_TCP_FORCE_5                   153658 non-null  float64\n",
      " 65  ROBOT_TCP_FORCE_6                   153658 non-null  float64\n",
      " 66  ROBOT_JOINT_TEMP_1                  153658 non-null  float64\n",
      " 67  ROBOT_JOINT_TEMP_2                  153658 non-null  float64\n",
      " 68  ROBOT_JOINT_TEMP_3                  153658 non-null  float64\n",
      " 69  ROBOT_JOINT_TEMP_4                  153658 non-null  float64\n",
      " 70  ROBOT_JOINT_TEMP_5                  153658 non-null  float64\n",
      " 71  ROBOT_JOINT_TEMP_6                  153658 non-null  float64\n",
      " 72  ROBOT_TIME                          153658 non-null  object \n",
      "dtypes: float64(72), object(1)\n",
      "memory usage: 98.5 MB\n"
     ]
    }
   ],
   "source": [
    "# ---Data Expansion ---\n",
    "\n",
    "# Columns covering all list-like fields that need expansion\n",
    "# Columns covering joint data (6 values each) and other list-like fields\n",
    "list_data_cols = [\n",
    "    \"ROBOT_TARGET_JOINT_POSITIONS\", \"ROBOT_ACTUAL_JOINT_POSITIONS\",\n",
    "    \"ROBOT_TARGET_JOINT_VELOCITIES\", \"ROBOT_ACTUAL_JOINT_VELOCITIES\",\n",
    "    \"ROBOT_TARGET_JOINT_CURRENTS\", \"ROBOT_ACTUAL_JOINT_CURRENTS\",\n",
    "    \"ROBOT_TARGET_JOINT_ACCELERATIONS\", \"ROBOT_TARGET_JOINT_TORQUES\",\n",
    "    \"ROBOT_JOINT_CONTROL_CURRENT\", \n",
    "    \"ROBOT_CARTESIAN_COORD_TOOL\",\n",
    "    \"ROBOT_TCP_FORCE\",\n",
    "    \"ROBOT_JOINT_TEMP\"\n",
    "]\n",
    "\n",
    "clean_sensor_data = expand_list_columns(sensor_data, list_data_cols)\n",
    "\n",
    "# Add scalar column (ROBOT_TIME) which was not in the list_data_cols\n",
    "scalar_cols = [\"ROBOT_TIME\"]\n",
    "clean_sensor_data = pd.concat([clean_sensor_data, sensor_data[scalar_cols]], axis=1)\n",
    "\n",
    "print(f\"‚úÖ Final shape after expansion: {clean_sensor_data.shape}\")\n",
    "print(\"\\nüìä Final Column Types and Memory Usage:\")\n",
    "clean_sensor_data.info(memory_usage=\"deep\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f691b1-4f94-40aa-ab6d-915b30f22dee",
   "metadata": {},
   "source": [
    "#### 2. Final Time Column Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ea93bd-5d79-4d1a-9f50-84331ab45504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-null count for ROBOT_TIME: 153658 out of 153658\n",
      "\n",
      "Final Data Types after Time Fix:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153658 entries, 0 to 153657\n",
      "Data columns (total 73 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   ROBOT_TARGET_JOINT_POSITIONS_1      153658 non-null  float64\n",
      " 1   ROBOT_TARGET_JOINT_POSITIONS_2      153658 non-null  float64\n",
      " 2   ROBOT_TARGET_JOINT_POSITIONS_3      153658 non-null  float64\n",
      " 3   ROBOT_TARGET_JOINT_POSITIONS_4      153658 non-null  float64\n",
      " 4   ROBOT_TARGET_JOINT_POSITIONS_5      153658 non-null  float64\n",
      " 5   ROBOT_TARGET_JOINT_POSITIONS_6      153658 non-null  float64\n",
      " 6   ROBOT_ACTUAL_JOINT_POSITIONS_1      153658 non-null  float64\n",
      " 7   ROBOT_ACTUAL_JOINT_POSITIONS_2      153658 non-null  float64\n",
      " 8   ROBOT_ACTUAL_JOINT_POSITIONS_3      153658 non-null  float64\n",
      " 9   ROBOT_ACTUAL_JOINT_POSITIONS_4      153658 non-null  float64\n",
      " 10  ROBOT_ACTUAL_JOINT_POSITIONS_5      153658 non-null  float64\n",
      " 11  ROBOT_ACTUAL_JOINT_POSITIONS_6      153658 non-null  float64\n",
      " 12  ROBOT_TARGET_JOINT_VELOCITIES_1     153658 non-null  float64\n",
      " 13  ROBOT_TARGET_JOINT_VELOCITIES_2     153658 non-null  float64\n",
      " 14  ROBOT_TARGET_JOINT_VELOCITIES_3     153658 non-null  float64\n",
      " 15  ROBOT_TARGET_JOINT_VELOCITIES_4     153658 non-null  float64\n",
      " 16  ROBOT_TARGET_JOINT_VELOCITIES_5     153658 non-null  float64\n",
      " 17  ROBOT_TARGET_JOINT_VELOCITIES_6     153658 non-null  float64\n",
      " 18  ROBOT_ACTUAL_JOINT_VELOCITIES_1     153658 non-null  float64\n",
      " 19  ROBOT_ACTUAL_JOINT_VELOCITIES_2     153658 non-null  float64\n",
      " 20  ROBOT_ACTUAL_JOINT_VELOCITIES_3     153658 non-null  float64\n",
      " 21  ROBOT_ACTUAL_JOINT_VELOCITIES_4     153658 non-null  float64\n",
      " 22  ROBOT_ACTUAL_JOINT_VELOCITIES_5     153658 non-null  float64\n",
      " 23  ROBOT_ACTUAL_JOINT_VELOCITIES_6     153658 non-null  float64\n",
      " 24  ROBOT_TARGET_JOINT_CURRENTS_1       153658 non-null  float64\n",
      " 25  ROBOT_TARGET_JOINT_CURRENTS_2       153658 non-null  float64\n",
      " 26  ROBOT_TARGET_JOINT_CURRENTS_3       153658 non-null  float64\n",
      " 27  ROBOT_TARGET_JOINT_CURRENTS_4       153658 non-null  float64\n",
      " 28  ROBOT_TARGET_JOINT_CURRENTS_5       153658 non-null  float64\n",
      " 29  ROBOT_TARGET_JOINT_CURRENTS_6       153658 non-null  float64\n",
      " 30  ROBOT_ACTUAL_JOINT_CURRENTS_1       153658 non-null  float64\n",
      " 31  ROBOT_ACTUAL_JOINT_CURRENTS_2       153658 non-null  float64\n",
      " 32  ROBOT_ACTUAL_JOINT_CURRENTS_3       153658 non-null  float64\n",
      " 33  ROBOT_ACTUAL_JOINT_CURRENTS_4       153658 non-null  float64\n",
      " 34  ROBOT_ACTUAL_JOINT_CURRENTS_5       153658 non-null  float64\n",
      " 35  ROBOT_ACTUAL_JOINT_CURRENTS_6       153658 non-null  float64\n",
      " 36  ROBOT_TARGET_JOINT_ACCELERATIONS_1  153658 non-null  float64\n",
      " 37  ROBOT_TARGET_JOINT_ACCELERATIONS_2  153658 non-null  float64\n",
      " 38  ROBOT_TARGET_JOINT_ACCELERATIONS_3  153658 non-null  float64\n",
      " 39  ROBOT_TARGET_JOINT_ACCELERATIONS_4  153658 non-null  float64\n",
      " 40  ROBOT_TARGET_JOINT_ACCELERATIONS_5  153658 non-null  float64\n",
      " 41  ROBOT_TARGET_JOINT_ACCELERATIONS_6  153658 non-null  float64\n",
      " 42  ROBOT_TARGET_JOINT_TORQUES_1        153658 non-null  float64\n",
      " 43  ROBOT_TARGET_JOINT_TORQUES_2        153658 non-null  float64\n",
      " 44  ROBOT_TARGET_JOINT_TORQUES_3        153658 non-null  float64\n",
      " 45  ROBOT_TARGET_JOINT_TORQUES_4        153658 non-null  float64\n",
      " 46  ROBOT_TARGET_JOINT_TORQUES_5        153658 non-null  float64\n",
      " 47  ROBOT_TARGET_JOINT_TORQUES_6        153658 non-null  float64\n",
      " 48  ROBOT_JOINT_CONTROL_CURRENT_1       153658 non-null  float64\n",
      " 49  ROBOT_JOINT_CONTROL_CURRENT_2       153658 non-null  float64\n",
      " 50  ROBOT_JOINT_CONTROL_CURRENT_3       153658 non-null  float64\n",
      " 51  ROBOT_JOINT_CONTROL_CURRENT_4       153658 non-null  float64\n",
      " 52  ROBOT_JOINT_CONTROL_CURRENT_5       153658 non-null  float64\n",
      " 53  ROBOT_JOINT_CONTROL_CURRENT_6       153658 non-null  float64\n",
      " 54  ROBOT_CARTESIAN_COORD_TOOL_1        153658 non-null  float64\n",
      " 55  ROBOT_CARTESIAN_COORD_TOOL_2        153658 non-null  float64\n",
      " 56  ROBOT_CARTESIAN_COORD_TOOL_3        153658 non-null  float64\n",
      " 57  ROBOT_CARTESIAN_COORD_TOOL_4        153658 non-null  float64\n",
      " 58  ROBOT_CARTESIAN_COORD_TOOL_5        153658 non-null  float64\n",
      " 59  ROBOT_CARTESIAN_COORD_TOOL_6        153658 non-null  float64\n",
      " 60  ROBOT_TCP_FORCE_1                   153658 non-null  float64\n",
      " 61  ROBOT_TCP_FORCE_2                   153658 non-null  float64\n",
      " 62  ROBOT_TCP_FORCE_3                   153658 non-null  float64\n",
      " 63  ROBOT_TCP_FORCE_4                   153658 non-null  float64\n",
      " 64  ROBOT_TCP_FORCE_5                   153658 non-null  float64\n",
      " 65  ROBOT_TCP_FORCE_6                   153658 non-null  float64\n",
      " 66  ROBOT_JOINT_TEMP_1                  153658 non-null  float64\n",
      " 67  ROBOT_JOINT_TEMP_2                  153658 non-null  float64\n",
      " 68  ROBOT_JOINT_TEMP_3                  153658 non-null  float64\n",
      " 69  ROBOT_JOINT_TEMP_4                  153658 non-null  float64\n",
      " 70  ROBOT_JOINT_TEMP_5                  153658 non-null  float64\n",
      " 71  ROBOT_JOINT_TEMP_6                  153658 non-null  float64\n",
      " 72  ROBOT_TIME                          153658 non-null  float64\n",
      "dtypes: float64(73)\n",
      "memory usage: 85.6 MB\n"
     ]
    }
   ],
   "source": [
    "time_col_name = 'ROBOT_TIME'\n",
    "\n",
    "# 1. Start with the data after expansion/concatenation, ensuring it's a string.\n",
    "clean_time_strings = clean_sensor_data[time_col_name].astype(str)\n",
    "\n",
    "# 2. Aggressive Cleaning: This is the robust fix.\n",
    "# It removes all non-numeric characters (brackets, quotes, spaces) to isolate the number.\n",
    "clean_time_strings = (\n",
    "    clean_time_strings\n",
    "    .str.strip()\n",
    "    # Regex removes EVERYTHING that is NOT a digit, decimal point, or negative sign\n",
    "    .str.replace(r'[^\\d.\\-]', '', regex=True) \n",
    ")\n",
    "\n",
    "# 3. Convert to numeric.\n",
    "fixed_time_data = pd.to_numeric(clean_time_strings, errors='coerce')\n",
    "\n",
    "# 4. Overwrite the column in the final expanded DataFrame.\n",
    "clean_sensor_data[time_col_name] = fixed_time_data\n",
    "\n",
    "# --- Final check ---\n",
    "time_non_null = clean_sensor_data[time_col_name].notna().sum()\n",
    "print(f\"Non-null count for ROBOT_TIME: {time_non_null} out of {len(clean_sensor_data)}\")\n",
    "print(\"\\nFinal Data Types after Time Fix:\")\n",
    "clean_sensor_data.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving_data_intro",
   "metadata": {},
   "source": [
    "## 5. üíæ Save Processed Data\n",
    "\n",
    "The expanded and structured sensor data is saved to the `../data/processed` directory in two formats for efficient use in downstream machine learning notebooks:\n",
    "\n",
    "* **CSV:** For standard interoperability.\n",
    "* **Parquet:** For highly efficient columnar storage, fast read/write speeds, and optimized memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "saving_data_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved processed dataset in Parquet and CSV formats.\n"
     ]
    }
   ],
   "source": [
    "# Create the directory if it doesn't exist\n",
    "processed_dir = \"../data/processed\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# 1. Save as Parquet (Highly recommended for speed and size in future notebooks)\n",
    "# Parquet is the best format for efficient loading in your next notebooks (02_data_preprocessing.ipynb, etc.).\n",
    "clean_sensor_data.to_parquet(f\"{processed_dir}/sensor_data_processed.parquet\", index=False)\n",
    "\n",
    "# 2. Save as CSV (For interoperability)\n",
    "clean_sensor_data.to_csv(f\"{processed_dir}/sensor_data_processed.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Saved processed dataset in Parquet and CSV formats.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "## 6. üßæ Summary\n",
    "\n",
    "This Exploratory Data Analysis (EDA) notebook successfully transformed the raw, non-standard UR5 sensor data into a clean, structured format.\n",
    "\n",
    "* **Data Merged:** All raw UR5 sensor CSV files were successfully merged.\n",
    "* **Data Volume:** The resulting dataset contains **~150K+ rows** of sensor readings.\n",
    "* **Feature Expansion:** All list-form sensor readings (e.g., joint positions, currents) were safely parsed and **expanded into 70+ individual numeric columns**.\n",
    "* **Dataset Ready:** The cleaned sensor data is now ready for deep analysis, feature creation, and merging with the summary/header data in the next phase.\n",
    "\n",
    "***\n",
    "\n",
    "**Next Notebook ‚Üí `02_feature_engineering.ipynb`**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Poetry: Manipulator-Health-Monitoring-EDA)",
   "language": "python",
   "name": "manipulator-health-monitoring-eda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
